{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import gcsfs\n",
    "xr.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Dask Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_kubernetes import KubeCluster\n",
    "cluster = KubeCluster(n_workers=1)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distributed\n",
    "from time import sleep, time\n",
    "\n",
    "def get_nworkers(cores_per_worker=2):\n",
    "    cl = distributed.get_client()\n",
    "    ncores = sum(cl.ncores().values())\n",
    "    return ncores // cores_per_worker\n",
    "\n",
    "def block_until_scaled(desired_workers):\n",
    "    cl = distributed.get_client()\n",
    "    cl.restart()\n",
    "    cl.cluster.scale(desired_workers)\n",
    "    while get_nworkers() != desired_workers:\n",
    "        sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_path = 'pangeo-data/esgf_test/pr_Amon_GFDL-CM4_piControl_r1i1p1f1_gr1'\n",
    "ds = xr.open_zarr(gcsfs.GCSMap(gc_path))\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Loading Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nworkers = [1, 2, 4, 8, 16]\n",
    "tc = 120\n",
    "rows = []\n",
    "for nw in nworkers:\n",
    "    block_until_scaled(nw)\n",
    "    total_data_size = ds.pr.nbytes/1e6\n",
    "    tic = time()\n",
    "    pr_mean = ds.pr.mean(dim='time').load()\n",
    "    runtime = time() - tic\n",
    "    row = (datetime.now(), nw, tc, runtime, total_data_size)\n",
    "    rows.append(row)\n",
    "    print(', '.join([repr(r) for r in row]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "columns = ['timestamp', 'nworkers', 'chunksize', 'runtime', 'datasize']\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('benchmark_zarr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
